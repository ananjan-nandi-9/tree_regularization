import argparse

def get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_load_path", type=str, default="", help="Path of model to resume training")
    parser.add_argument("--save_dir", type=str, default="checkpoints", help="")
    parser.add_argument("--dataset", type=str, default="cogs")
    parser.add_argument("--parse_dataset", type=str, default="None", help="Set if TreeReg is to use another dataset")
    parser.add_argument("--vec_dim", type=int, default=512)
    parser.add_argument("--gpu_id", type=int, default=0)
    parser.add_argument("--n_heads", type=int, default=8)
    parser.add_argument("--encoder_n_layers", type=int, default=6)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--start_lr", type=float, default=6e-4)
    parser.add_argument("--end_lr", type=float, default=0)
    parser.add_argument("--relative", type=bool, default=False, help="Set to use relative positional encodings")
    parser.add_argument("--pack", action="store_true", help="Implement packing to max_seq_len.")
    parser.add_argument("--max_seq_len", type=int, default=1024)
    parser.add_argument("--hf", action="store_true", help="Use a model from HuggingFace.")
    parser.add_argument("--hf_model_name", type=str, default="princeton-nlp/Sheared-LLaMA-1.3B")
    parser.add_argument("--nanogpt", action="store_true", help="GPT2 mode")

    parser.add_argument("--regularize", action="store_true", help="Turn on tree regularization.")
    parser.add_argument("--parse_portion", type=float, default=1.0, help="Percentage of parsed data to be used.")
    parser.add_argument("--regularizer_steps", type=int, default=2, help="Regularize every regularizer_steps training steps.")
    parser.add_argument("--layer_id", type=int, default=-1, help="Layer to apply TreeReg at")
    parser.add_argument("--orth_bidir", action="store_true", help="Bidirectional SCI computation")
    parser.add_argument("--treereg_same_data", action="store_true", help="Is TreeReg and LM done on the same data?")
    parser.add_argument("--sci_heads", type=float, default=-1., help="Proportion of attention heads to be used in SCI computation")

    parser.add_argument("--batch_size", type=int, default=32)
    parser.add_argument("--accum_steps", type=int, default=1)
    parser.add_argument("--embedding_dropout", type=float, default=-1.0)
    parser.add_argument("--output_dropout", type=float, default=-1.0)
    parser.add_argument("--batch_size_eval", type=int, default=32)
    parser.add_argument("--weight_decay", type=float, default=0.0)
    parser.add_argument("--eval_every", type=int, default=10000)
    parser.add_argument("--max_train_steps", type=int, default=20000)
    parser.add_argument("--save_interval", type=int, default=10000)
    parser.add_argument("--wandb_project", type=str, default="structural-grokking")
    parser.add_argument("--wandb_entity", type=str, default="tgk-ananjan", required=True)
    parser.add_argument("--callback", action="store_true")

    return parser